[
  {
    "objectID": "day4_exercises.html",
    "href": "day4_exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "Specify a model in which you investigate whether the group means can be constrained across time. Tip: Allow all variables to covary with each other (i.e. specify a model without constraints on the covariance structure) such that we are estimating means, and not intercepts.\n\n\nDoes this model fit?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe model specification is given in exercise1A.inp on SURFdrive. The model does not fit well, according to the \\(\\chi^{2}\\) and the RMSEA; CFI and TLI indicate a good and barely acceptable model fit, respectively. See the slides of day 1 of this summer school if you need a refresher on the recommended cutoff values for these fit indices (although such cutoff recommendations remain a hotly debated topic among statisticians).\n\n\\(\\chi^{2}\\) (4) = 19.620, \\(p &lt; .001\\)\nRMSEA = 0.099\nCFI = 0.986\nTLI = 0.946\n\n\n\n\n\n\n\nWhat can you do to improve the model fit?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe can look at the modification indices in the output. Here, we specified MOD(4) in the OUTPUT command, which indicates all parameters that can be added/freed that will lead to a decrease in chi-square of at least 4 points (which is a significant improvement combined with 1 df).\nBased on the Mplus output, it appears that freeing the mean of Dep1 leads to the largest change in chi-square (M.I. = 10.53).\n\n\n\n\n\n\nRun the adjusted model and discuss the results.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSyntax for the adjusted model is in exercise1C.inp. Looking at the fit indices of the adjusted model, the chi-square for this model is still significant, but all other measures indicate the model fit is okay to excellent. Moreover, the model is a significant improvement in comparison to the previous model: \\(\\Delta\\chi^{2} = 19.62 - 8.71 = 10.91\\), with \\(\\Delta\\)df = 1 and, \\(p = .001\\).\nYou can calculate the p-value of the \\(\\Delta \\chi^{2}\\) using the pchisq()-function in R (with the lower.tail argument set to FALSE), or an online tool"
  },
  {
    "objectID": "day4_exercises.html#mean-structure",
    "href": "day4_exercises.html#mean-structure",
    "title": "Exercises",
    "section": "",
    "text": "Specify a model in which you investigate whether the group means can be constrained across time. Tip: Allow all variables to covary with each other (i.e. specify a model without constraints on the covariance structure) such that we are estimating means, and not intercepts.\n\n\nDoes this model fit?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe model specification is given in exercise1A.inp on SURFdrive. The model does not fit well, according to the \\(\\chi^{2}\\) and the RMSEA; CFI and TLI indicate a good and barely acceptable model fit, respectively. See the slides of day 1 of this summer school if you need a refresher on the recommended cutoff values for these fit indices (although such cutoff recommendations remain a hotly debated topic among statisticians).\n\n\\(\\chi^{2}\\) (4) = 19.620, \\(p &lt; .001\\)\nRMSEA = 0.099\nCFI = 0.986\nTLI = 0.946\n\n\n\n\n\n\n\nWhat can you do to improve the model fit?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe can look at the modification indices in the output. Here, we specified MOD(4) in the OUTPUT command, which indicates all parameters that can be added/freed that will lead to a decrease in chi-square of at least 4 points (which is a significant improvement combined with 1 df).\nBased on the Mplus output, it appears that freeing the mean of Dep1 leads to the largest change in chi-square (M.I. = 10.53).\n\n\n\n\n\n\nRun the adjusted model and discuss the results.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSyntax for the adjusted model is in exercise1C.inp. Looking at the fit indices of the adjusted model, the chi-square for this model is still significant, but all other measures indicate the model fit is okay to excellent. Moreover, the model is a significant improvement in comparison to the previous model: \\(\\Delta\\chi^{2} = 19.62 - 8.71 = 10.91\\), with \\(\\Delta\\)df = 1 and, \\(p = .001\\).\nYou can calculate the p-value of the \\(\\Delta \\chi^{2}\\) using the pchisq()-function in R (with the lower.tail argument set to FALSE), or an online tool"
  },
  {
    "objectID": "day4_exercises.html#the-clpm",
    "href": "day4_exercises.html#the-clpm",
    "title": "Exercises",
    "section": "The CLPM",
    "text": "The CLPM\n\nExercise 2A\nSpecify the cross-lagged panel model (CLPM) in Mplus. Regress the observed variables directly on each other over time, as in the graph above. Try to think of where each parameter you estimate should go in the graph. Compare your model specification with the input file exercise2A.inp in SURFdrive.\n\n\n\nThe cross-lagged panel model.\n\n\n\n\nExercise 2B\nSpecify the model as in the graph below (the CLPM with centered latent variables), and again include the (significant) parameter estimates in this graph. Tip: Do not forget to constrain the measurement error variances of the observed variables to 0. Compare your model specification with the input file exercise2B.inp in SURFdrive.\n\n\n\nThe cross-lagged panel model with centered latent variables.\n\n\n\n\nExercise 2C\nThe two models should lead to the exact same model fit. Estimate the model and discuss the model fit. When comparing the parameter estimates, what is the difference between the model in exercise 2A and the model in exercise 2B?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe CLPM with centered latent variables is, just like the CLPM from exercise 2A, a traditional CLPM, but specified in such a way that the mean structure is first separated from the regression part of the model. This implies we model the means, rather than intercepts, which makes it easier to impose the constraint of identical means over time. So, the fit indices and most parameter estimates are equivalent, except for… (see next question)\n\n\n\n\n\nExercise 2D\nWhich parameter estimates differ? How can they be related?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe difference in parameter estimates is in the means/intercepts. For the first model we estimate the means at wave 1, and intercepts thereafter. For the second model we obtain mean estimates at each wave (although they are referred to as intercepts in the Mplus output).\nAgain, the reason for this is that in the first model, the means at wave 2 and 3 are partly predicted by the means from previous waves (through the lagged relationships). Therefore, the constants that are estimated should be interpreted as intercepts. In the second model, the mean part (triangles) and the regression part (lagged parameters) are separated.\n\n\n\n\n\nExercise 2E\nConstrain the means in the second version of the CLPM. Please do not constrain the mean of Dep1, however, as this constraint proved untenable in exercise 1C. Discuss the model fit.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe input for these models are in exercise2E.inp. The chi-square has increased in comparison with the previous model: The reason is that this is a restricted model (a special case of the previous model). We can test whether the increase in misfit is significant using the chi-square difference test: \\(\\Delta\\chi^{2} = 69.59 - 62.98 = 6.61\\) with \\(\\Delta\\)df = 7 – 4 = 3, \\(p = .0854\\). Hence, the constraints are tenable. We can also look at information criteria such as the AIC or BIC. The model with the lowest AIC or BIC is preferred.\n\n\n\n\n\nExercise 2F\nContinue with the model from the previous question and constrain all the lagged parameters between wave 1 and 2 to be identical to the lagged parameters between wave 2 and 3. Discuss the model fit, and compare this model to the previous one to see whether the constraint holds.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe input for these models are in CLPMalt3.inp. The chi-square has again increased in comparison with the previous model: The reason is that this is a restricted model (a special case of the previous model). We can test whether the increase in misfit is significant: \\(\\Delta\\chi^{2} 81.52 - 69.59 = 11.93\\), \\(\\Delta\\)(df) = 11 - 7 = 4, \\(p = .0178\\).\nIf we stick to an alpha of .05, the constraints must be rejected (as the increase in misfit is significant). Note that we are doing several model comparisons here, so one could also argue that we should use a smaller alpha to guard against an inflated overall type I error. Again, an alternative would be to use information criteria for model comparisons."
  },
  {
    "objectID": "day4_exercises.html#the-ri-clpm",
    "href": "day4_exercises.html#the-ri-clpm",
    "title": "Exercises",
    "section": "The RI-CLPM",
    "text": "The RI-CLPM\n\nExercise 3A\nSpecify the RI-CLPM for these data (without any constraints on the lagged parameters over time). Discuss the model fit.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe input for these models are in exercise3A.inp. This model fits very well; however, it only has 1 df, so it is not doing much for data reduction.\n\n\n\n\n\nExercise 3B\nSpecify the RI-CLPM with the constraints on the grand means at each occasions. Again, please do not constrain the mean of Dep1, however, as this constraint proved untenable in exercise 3.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe input for these models are in exercise3B.inp. This model has an acceptable (RMSEA, \\(\\chi^{2}\\)) to good (CFI and TLI) fit. Comparing it to the previous model, we get a chi-square difference test of \\(\\Delta\\chi^{2} = 9.590 - 0.84 = 8.75\\), \\(\\Delta\\)df = 4 - 1 = 3, \\(p = .0328\\). This implies that the constraints we impose on the means are untenable (they lead to a significant worsening of model fit). You might therefore decide to ultimately not impose these constraints. However, for didactical reasons, we continue with these constraints in place in the next exercise.\n\n\n\n\n\nExercise 3C\nAdd the constraints on the lagged parameters to the previous model.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe input for these models are in exercise3C.inp. This model fits okay (depending on the measure). Comparing it to the previous model, we get \\(\\Delta\\chi^{2} = 19.74 - 9.59 = 8.15\\), \\(\\Delta\\)df = 8 - 4 = 4, \\(p = .0379\\). Again, this implies that constraining the lagged effects to be time-invariant is untenable (it leads to a significant worsening of model fit).\n\n\n\n\n\nExercise 3D\nCompare all the models so far simultaneously, using the AIC and BIC. Which model is selected?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBased on the AIC, the RI-CLPM without any constraints provides the closest fit to the data, followed by the two other RI-CLPMs (and the adjusted means model). Based on the BIC, the RI-CLPM with constraints on the means and the lagged parameters is superior to the other models.\n\n\n\nExercise\nInput file\nAIC\nBIC\n\n\n\n\n1\nexercise1A.inp\n9451\n9543\n\n\n3\nexercise1C.inp\n9442\n9538\n\n\n6\nexercise2A.inp and exercise2B.inp\n9494\n9586\n\n\n7\nexercise2E.inp\n9495\n9575\n\n\n8\nexercise2F.inp\n9499\n9563\n\n\n9\nexercise3A.inp\n9438\n9541\n\n\n10\nexercise3B.inp\n9441\n9533\n\n\n11\nexercise3C.inp\n9443\n9518"
  },
  {
    "objectID": "day4_introduction.html",
    "href": "day4_introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "In this computer lab are going to analyze the same data that were used in the Hamaker et al. (2015) paper and were presented in the lecture. The goals of these exercises are to get some experience with fitting (random intercept) cross-lagged panel models, interpreting their results, and comparing them. Here, we focus on the relationship between Parental Responsiveness and Adolescents’ Depressive Symptomatology (note, in the lecture the focus was on a different concept, namely Parental Psychological Control).\nThe data (means, standard deviations, and the correlation matrix) are included in the file Soenens.dat on SURFdrive. The number of observations is 396. The data command for these data should be:\nDATA:       \n  TYPE = MEANS STDEVIATIONS CORRELATION;   \n  FILE = Soenens.dat;\n  NOBSERVATIONS = 396;\nThe variable command should be:\nVARIABLE:   \n  NAMES = PsCon1-PsCon3 Res1-Res3 BeCon1-BeCon3 Dep1-Dep3;\n  USEVARIABLES = Res1 Dep1 Res2 Dep2 Res3 Dep3;\nDo the exercises. You can navigate through them using the left-hand menu or the arrows on left- and right-hand side of this screen. Answers are included below each exercise. The Mplus input files can found in the SURFdrive folder."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Structural Equation Modeling using Mplus",
    "section": "",
    "text": "These course materials are part of the course Introduction to Structural Equation Modeling using Mplus (S20). It is a five-day summer school course hosted by Utrecht University’s department of Methodology and Statistics. The main objective is to learn how to analyze several models with Mplus (e.g. path models, multiple group models, mediation and moderation, confirmatory factor analysis, and longitudinal models). More in-depth lectures on the fundamentals of Mplus and advanced longitudinal models are discussed in the advanced course (S23).\nUsing the menu on the left, you can navigate to the exercises of each day."
  },
  {
    "objectID": "day3_part1.html",
    "href": "day3_part1.html",
    "title": "Part 1: Factor analysis and nested model check",
    "section": "",
    "text": "Suppose there are three researchers who are investigating the underlying factor structure of psychopathology (i.e., mental illness). The data (file: ex5.6.dat) they have obtained consists of 12 items, where:\n\nAnx1, Anx2, and Anx3 measure anxiety;\nDep1, Dep2, and Dep3 measure depression;\nAdd1, Add2, and Add3 measure addictive behaviors;\nCon1, Con2, and Con3 measure conflict behaviors.\n\nThe four researchers have different ideas about how these data should be modeled. Their ideas are depicted and described below.\nResearcher 1 assumes that there is one general psychopathology factor P, and that there are four unique (and uncorrelated) factors for the four different clusters of items. Such a model is known as the bi-factor model.\n\n\n\nThe bi-factor model.\n\n\nResearcher 2 assumes that the best way to describe these data is by use of a 4-factor model, in which these factors are allowed to covary.\n\n\n\nThe 4-factor model.\n\n\nResearcher 3 also believes there is a general factor P, but assumes this is a factor that relates the other four factors. This is known as a second-order factor model.\n\n\n\nThe second-order factor model.\n\n\nResearcher 4 thinks the approach should be simpler and assumes there are two factors: An internalizing factor (consisting of the anxiety and depression items), and an externalizing factor (consisting of the addiction and conflict items). This is the two-factor model.\n\n\n\nThe second-order factor model.\n\n\n\nExercise 1\nSpecify each of these models in Mplus, and add the missing information to the table below. You can use the number of free parameters and/or the number of df to check whether you specified the model correctly.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n\n\n\nModel\nFree parameters\ndf\n\\(\\chi^{2}\\)\np-value\n\n\n\n\nbi-factor model\n48\n42\n41.64\n.487\n\n\n4-factor model\n42\n48\n45.78\n.564\n\n\nsecond-order factor model\n40\n50\n46.74\n.605\n\n\n2-factor model\n37\n53\n1780.55\n\\(&lt;\\).001\n\n\n\n\n\n\n\n\nExercise 2\nThe researchers want to compare the models using a \\(\\Delta \\chi^{2}\\)-test, if possible. Can you help these researchers figure out whether or not these models are nested? Note that a necessary but not sufficient condition for nesting is that the nested (more parsimonious model) has fewer free parameters (thus more df) than the more general model. Hence, based on the number of free parameters, we can make the following comparisons:\n\n\n\nMore general model\nMore parsimonious model(s)\nNested?\n\n\n\n\nbi-factor model\n4-factor model\n…\n\n\nbi-factor model\nsecond-order factor model\n…\n\n\nbi-factor model\n2-factor model\n…\n\n\n4-factor model\nsecond-order factor model\n…\n\n\n4-factor model\n2-factor model\n…\n\n\nsecond-order factor model\n2-factor model\n…\n\n\n\nPerform the nesting checks included in the table and indicate for each whether the models are nested. Use this information in the figure below to indicate for each arrow whether or not the models are nested.\n\n\n\n\n\n\n\nImportant: The SAVEDATA command\n\n\n\n\n\nTo compare the models, first run the most parsimonious model and save data for a nested test by adding to following command to your syntax:\nSAVEDATA: NESTED = 2factormodel.dat;\nIf you are using Mplus via SolisWorkspace, then you need to explicitly specify the path to which you want to save the 2factormodel.dat to for this command to work. Mplus will throw an error if you fail to do this. Specify a path within apostrophes (“ “) and do not forget to end the command with a semi-colon. You can find the path within Mplus by going to the File-menu, and clicking on ‘Open…’. Navigate to the folder where you want to save the .dat-file in, and copy the path in the navigation bar. Paste this path within the apostrophes in the SAVEDATA command, and extend with the name that you want to give the .dat-file.\nThe SAVEDATA-command should be something like:\nSAVEDATA: NESTED = \"\\\\Client\\C$\\Users\\...\n          …S20 - Day 3\\Exercise 1\\2factormodel.dat\";\nCommands in Mplus must not exceed 90 characters per line. So if your path is quite long, don’t forget to break up your command (before the 90\\(^{th}\\) character) and continue on a second (or third, etc.) line. See the example above. Then run the model that that is more general, and perform the nested test by adding (here you don’t need to explicitly specify the path to the .dat-file):\nANALYSIS: NESTED = 2factormodel.dat;\nThis gives you the following output under the fit statistics (just above the SRMR):\nNested Model Check\n\n          Result                        Not Nested\n          Fit Function Value            0.09146430\nThis implies that the 2-factor model of research 4 is not a special case of the second-order factor model of researcher 3.\n\n\n\n\n\n\n\n\n\nAnswer\n\n\n\n\n\n Take home message:\n\nConclusion 1: Parsimony—while a necessary condition—is not a sufficient condition for nesting.\nConclusion 2: Models that look quite different, may nevertheless be nested."
  },
  {
    "objectID": "day3_exercises.html",
    "href": "day3_exercises.html",
    "title": "Part 2: Full SEM, with mediation and moderation",
    "section": "",
    "text": "Two researchers are interested in burnout among academics. They have obtained the data (file: Ex2sim.dat) from 300 academics on the following variables:\nThe researchers want to investigate whether the detrimental effect of Emotional Exhaustion on Academic Achievement is mediated by Cynicism. They also want to control for differences between men and women in Emotional Exhaustion, Cynicism, and Academic Achievement. Hence, they propose the following model:\nNote that, even though Fem is a categorical variable (with scores 0 or 1), we do not have to treat it differently in Mplus than the continuous variables because:"
  },
  {
    "objectID": "day3_exercises.html#mean-structure",
    "href": "day3_exercises.html#mean-structure",
    "title": "Exercises",
    "section": "",
    "text": "Specify a model in which you investigate whether the group means can be constrained across time. Tip: Allow all variables to covary with each other (i.e. specify a model without constraints on the covariance structure) such that we are estimating means, and not intercepts.\n\n\nDoes this model fit?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe model specification is given in exercise1A.inp on SURFdrive. The model does not fit well, according to the \\(\\chi^{2}\\) and the RMSEA; CFI and TLI indicate a good and barely acceptable model fit, respectively. See the slides of day 1 of this summer school if you need a refresher on the recommended cutoff values for these fit indices (although such cutoff recommendations remain a hotly debated topic among statisticians).\n\n\\(\\chi^{2}\\) (4) = 19.620, \\(p &lt; .001\\)\nRMSEA = 0.099\nCFI = 0.986\nTLI = 0.946\n\n\n\n\n\n\n\nWhat can you do to improve the model fit?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nWe can look at the modification indices in the output. Here, we specified MOD(4) in the OUTPUT command, which indicates all parameters that can be added/freed that will lead to a decrease in chi-square of at least 4 points (which is a significant improvement combined with 1 df).\nBased on the Mplus output, it appears that freeing the mean of Dep1 leads to the largest change in chi-square (M.I. = 10.53).\n\n\n\n\n\n\nRun the adjusted model and discuss the results.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSyntax for the adjusted model is in exercise1C.inp. Looking at the fit indices of the adjusted model, the chi-square for this model is still significant, but all other measures indicate the model fit is okay to excellent. Moreover, the model is a significant improvement in comparison to the previous model: \\(\\Delta\\chi^{2} = 19.62 - 8.71 = 10.91\\), with \\(\\Delta\\)df = 1 and, \\(p = .001\\).\nYou can calculate the p-value of the \\(\\Delta \\chi^{2}\\) using the pchisq()-function in R (with the lower.tail argument set to FALSE), or an online tool"
  },
  {
    "objectID": "day3_exercises.html#the-clpm",
    "href": "day3_exercises.html#the-clpm",
    "title": "Exercises",
    "section": "The CLPM",
    "text": "The CLPM\n\nExercise 2A\nSpecify the cross-lagged panel model (CLPM) in Mplus. Regress the observed variables directly on each other over time, as in the graph above. Try to think of where each parameter you estimate should go in the graph. Compare your model specification with the input file exercise2A.inp in SURFdrive.\n\n\n\nThe cross-lagged panel model.\n\n\n\n\nExercise 2B\nSpecify the model as in the graph below (the CLPM with centered latent variables), and again include the (significant) parameter estimates in this graph. Tip: Do not forget to constrain the measurement error variances of the observed variables to 0. Compare your model specification with the input file exercise2B.inp in SURFdrive.\n\n\n\nThe cross-lagged panel model with centered latent variables.\n\n\n\n\nExercise 2C\nThe two models should lead to the exact same model fit. Estimate the model and discuss the model fit. When comparing the parameter estimates, what is the difference between the model in exercise 2A and the model in exercise 2B?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe CLPM with centered latent variables is, just like the CLPM from exercise 2A, a traditional CLPM, but specified in such a way that the mean structure is first separated from the regression part of the model. This implies we model the means, rather than intercepts, which makes it easier to impose the constraint of identical means over time. So, the fit indices and most parameter estimates are equivalent, except for… (see next question)\n\n\n\n\n\nExercise 2D\nWhich parameter estimates differ? How can they be related?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe difference in parameter estimates is in the means/intercepts. For the first model we estimate the means at wave 1, and intercepts thereafter. For the second model we obtain mean estimates at each wave (although they are referred to as intercepts in the Mplus output).\nAgain, the reason for this is that in the first model, the means at wave 2 and 3 are partly predicted by the means from previous waves (through the lagged relationships). Therefore, the constants that are estimated should be interpreted as intercepts. In the second model, the mean part (triangles) and the regression part (lagged parameters) are separated.\n\n\n\n\n\nExercise 2E\nConstrain the means in the second version of the CLPM. Please do not constrain the mean of Dep1, however, as this constraint proved untenable in exercise 1C. Discuss the model fit.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe input for these models are in exercise2E.inp. The chi-square has increased in comparison with the previous model: The reason is that this is a restricted model (a special case of the previous model). We can test whether the increase in misfit is significant using the chi-square difference test: \\(\\Delta\\chi^{2} = 69.59 - 62.98 = 6.61\\) with \\(\\Delta\\)df = 7 – 4 = 3, \\(p = .0854\\). Hence, the constraints are tenable. We can also look at information criteria such as the AIC or BIC. The model with the lowest AIC or BIC is preferred.\n\n\n\n\n\nExercise 2F\nContinue with the model from the previous question and constrain all the lagged parameters between wave 1 and 2 to be identical to the lagged parameters between wave 2 and 3. Discuss the model fit, and compare this model to the previous one to see whether the constraint holds.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe input for these models are in CLPMalt3.inp. The chi-square has again increased in comparison with the previous model: The reason is that this is a restricted model (a special case of the previous model). We can test whether the increase in misfit is significant: \\(\\Delta\\chi^{2} 81.52 - 69.59 = 11.93\\), \\(\\Delta\\)(df) = 11 - 7 = 4, \\(p = .0178\\).\nIf we stick to an alpha of .05, the constraints must be rejected (as the increase in misfit is significant). Note that we are doing several model comparisons here, so one could also argue that we should use a smaller alpha to guard against an inflated overall type I error. Again, an alternative would be to use information criteria for model comparisons."
  },
  {
    "objectID": "day3_exercises.html#the-ri-clpm",
    "href": "day3_exercises.html#the-ri-clpm",
    "title": "Exercises",
    "section": "The RI-CLPM",
    "text": "The RI-CLPM\n\nExercise 3A\nSpecify the RI-CLPM for these data (without any constraints on the lagged parameters over time). Discuss the model fit.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe input for these models are in exercise3A.inp. This model fits very well; however, it only has 1 df, so it is not doing much for data reduction.\n\n\n\n\n\nExercise 3B\nSpecify the RI-CLPM with the constraints on the grand means at each occasions. Again, please do not constrain the mean of Dep1, however, as this constraint proved untenable in exercise 3.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe input for these models are in exercise3B.inp. This model has an acceptable (RMSEA, \\(\\chi^{2}\\)) to good (CFI and TLI) fit. Comparing it to the previous model, we get a chi-square difference test of \\(\\Delta\\chi^{2} = 9.590 - 0.84 = 8.75\\), \\(\\Delta\\)df = 4 - 1 = 3, \\(p = .0328\\). This implies that the constraints we impose on the means are untenable (they lead to a significant worsening of model fit). You might therefore decide to ultimately not impose these constraints. However, for didactical reasons, we continue with these constraints in place in the next exercise.\n\n\n\n\n\nExercise 3C\nAdd the constraints on the lagged parameters to the previous model.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nThe input for these models are in exercise3C.inp. This model fits okay (depending on the measure). Comparing it to the previous model, we get \\(\\Delta\\chi^{2} = 19.74 - 9.59 = 8.15\\), \\(\\Delta\\)df = 8 - 4 = 4, \\(p = .0379\\). Again, this implies that constraining the lagged effects to be time-invariant is untenable (it leads to a significant worsening of model fit).\n\n\n\n\n\nExercise 3D\nCompare all the models so far simultaneously, using the AIC and BIC. Which model is selected?\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nBased on the AIC, the RI-CLPM without any constraints provides the closest fit to the data, followed by the two other RI-CLPMs (and the adjusted means model). Based on the BIC, the RI-CLPM with constraints on the means and the lagged parameters is superior to the other models.\n\n\n\nExercise\nInput file\nAIC\nBIC\n\n\n\n\n1\nexercise1A.inp\n9451\n9543\n\n\n3\nexercise1C.inp\n9442\n9538\n\n\n6\nexercise2A.inp and exercise2B.inp\n9494\n9586\n\n\n7\nexercise2E.inp\n9495\n9575\n\n\n8\nexercise2F.inp\n9499\n9563\n\n\n9\nexercise3A.inp\n9438\n9541\n\n\n10\nexercise3B.inp\n9441\n9533\n\n\n11\nexercise3C.inp\n9443\n9518"
  },
  {
    "objectID": "day3_exercises.html#exercise-1",
    "href": "day3_exercises.html#exercise-1",
    "title": "Part 2: Full SEM, with mediation and moderation",
    "section": "Exercise 1",
    "text": "Exercise 1\nSpecify this model and discuss the model fit."
  },
  {
    "objectID": "day3_exercises.html#exercise-2",
    "href": "day3_exercises.html#exercise-2",
    "title": "Part 2: Full SEM, with mediation and moderation",
    "section": "Exercise 2",
    "text": "Exercise 2\nInvestigate whether there is an indirect (mediated) effect of Emotional Exhaustion on Academic Achievement. Remember to use the MODEL INDIRECT command, and combine this with bootstrapping and confidence intervals (see slides)."
  },
  {
    "objectID": "day3_exercises.html#exercise-3",
    "href": "day3_exercises.html#exercise-3",
    "title": "Part 2: Full SEM, with mediation and moderation",
    "section": "Exercise 3",
    "text": "Exercise 3\nDo the same for the effect of being female on academic achievement."
  },
  {
    "objectID": "day3_exercises.html#exercise-4",
    "href": "day3_exercises.html#exercise-4",
    "title": "Part 2: Full SEM, with mediation and moderation",
    "section": "Exercise 4",
    "text": "Exercise 4\nThe researchers are also interested in investigating whether there is an interaction between being female and emotional exhaustion on cynicism; specifically, they want to know whether the effect of emotional exhaustion on cynicism is stronger for males than for females. The model they want to specify for this is visualized below:\n\nRemember that to specify an interaction between an observed and a latent variable (indicated here by the black dot) in Mplus, you need to use the XWITH statement in the MODEL command. The use of this statement requires you to use (see slides):\nANALYSIS:   TYPE = RANDOM; \n            ALGORITHM = INTEGRATION; \nNote that this cannot be combined with bootstrapping, or the MODEL INDIRECT command (you get error messages when you try to do this). The latter does not imply there are no indirect effects in the model; it merely implies you cannot get the additional output for this.\nSpecify this model in Mplus"
  },
  {
    "objectID": "day3_exercises.html#exercise-5",
    "href": "day3_exercises.html#exercise-5",
    "title": "Part 2: Full SEM, with mediation and moderation",
    "section": "Exercise 5",
    "text": "Exercise 5\nWe now have a slope for males and a difference in slopes between males and females. If instead, we are interested in the actual slope of females, we can ask Mplus to compute this as an additional statistic using the MODEL CONSTRAINT command. To this end, we first need to name the slopes of interest, using\nCynicism ON EmEx Fem EExF (slopeM interDiff slopeDiff);  \nand subsequently we can use these names to compute new statistic, using\nMODEL CONSTRAINT:\n      new(slopeF);\n      slopeF = slopeM + slopeDiff;\nThis way we will obtain the estimate for the slope of females, including its standard error and p-value. Specify this model in Mplus, and report the results."
  },
  {
    "objectID": "day3_part2.html",
    "href": "day3_part2.html",
    "title": "Part 2: Full SEM, with mediation and moderation",
    "section": "",
    "text": "Two researchers are interested in burnout among academics. They have obtained the data (file: Ex2sim.dat) from 300 academics on the following variables:\nThe researchers want to investigate whether the detrimental effect of Emotional Exhaustion on Academic Achievement is mediated by Cynicism. They also want to control for differences between men and women in Emotional Exhaustion, Cynicism, and Academic Achievement. Hence, they propose the following model:\nNote that, even though Fem is a categorical variable (with scores 0 or 1), we do not have to treat it differently in Mplus than the continuous variables because:"
  },
  {
    "objectID": "day3_part2.html#exercise-1",
    "href": "day3_part2.html#exercise-1",
    "title": "Part 2: Full SEM, with mediation and moderation",
    "section": "Exercise 1",
    "text": "Exercise 1\nSpecify this model and discuss the model fit.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSee the Ex2Model1.out file. The \\(\\chi^{2}\\) test indicate that the model does not fit, \\(\\chi^{2} (16) = 33.06\\), \\(p = .0073\\). Other measures indicate acceptable model fit: RMSEA is 0.06, CFI is 0.96, TLI is 0.93, and SRMR is 0.04."
  },
  {
    "objectID": "day3_part2.html#exercise-2",
    "href": "day3_part2.html#exercise-2",
    "title": "Part 2: Full SEM, with mediation and moderation",
    "section": "Exercise 2",
    "text": "Exercise 2\nInvestigate whether there is an indirect (mediated) effect of Emotional Exhaustion on Academic Achievement. Remember to use the MODEL INDIRECT command, and combine this with bootstrapping and confidence intervals (see slides).\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSee the Ex2Model2.out file. To interpret the size of a (significant) effect, it is helpful to use the standardized results. When looking at the p-values for the standardized (bootstrap) results, we find:\n\nTotal effect is significant: -0.152 (SE = 0.067, \\(p = .023\\))\nIndirect effect is not significant: -0.071 (SE = 0.038, \\(p = .058\\))\nDirect effect is not significant: -0.081 (SE = 0.068, \\(p = .234\\))\n\nNote that the total effect is the sum of the indirect and the direct effects: \\(-0.152 = (-0.071) + (-0.081)\\). The results here show that, while we do not have the power to detect a direct or an indirect effect, the total effect is significant.\nThe 95% confidence intervals for the standardized effects are:\n\nTotal effect (-0.283,-0.021); does not contain zero\nIndirect effect (-0.145,0.002); contains zero\nDirect effect (-0.213,0.052); contains zero\n\nHence, the conclusions based on the confidence intervals are the same as the conclusions based on the p-values."
  },
  {
    "objectID": "day3_part2.html#exercise-3",
    "href": "day3_part2.html#exercise-3",
    "title": "Part 2: Full SEM, with mediation and moderation",
    "section": "Exercise 3",
    "text": "Exercise 3\nDo the same for the effect of being female on academic achievement.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nMoving to the confidence intervals for standardized parameters right away, we find:\n\nTotal effect is -0.020, 95% CI [-0.131, 0.090]; contains zero\nIndirect effect FEM \\(\\rightarrow\\) Cynicism \\(\\rightarrow\\) AcAch is 0.038, 95% CI [-0.014, 0.091]; contains zero\nIndirect effect FEM \\(\\rightarrow\\) EMEX \\(\\rightarrow\\) AcAch is -0.013, 95% CI [-0.038, 0.013]; contains zero\nIndirect effect FEM \\(\\rightarrow\\) EMEX \\(\\rightarrow\\) Cynicism \\(\\rightarrow\\) AcAch is -0.011, 95% CI [-0.028, 0.005]; contains zero\nDirect effect is -0.035, 95% CI [-0.153,0.084]; contains zero.\n\nConclusion: there is no evidence that being female has a direct or indirect effect on academic achievement."
  },
  {
    "objectID": "day3_part2.html#exercise-4",
    "href": "day3_part2.html#exercise-4",
    "title": "Part 2: Full SEM, with mediation and moderation",
    "section": "Exercise 4",
    "text": "Exercise 4\nThe researchers are also interested in investigating whether there is an interaction between being female and emotional exhaustion on cynicism; specifically, they want to know whether the effect of emotional exhaustion on cynicism is stronger for males than for females. The model they want to specify for this is visualized below:\n\nRemember that to specify an interaction between an observed and a latent variable (indicated here by the black dot) in Mplus, you need to use the XWITH statement in the MODEL command. The use of this statement requires you to use (see slides):\nANALYSIS:   TYPE = RANDOM; \n            ALGORITHM = INTEGRATION; \nNote that this cannot be combined with bootstrapping, or the MODEL INDIRECT command (you get error messages when you try to do this). The latter does not imply there are no indirect effects in the model; it merely implies you cannot get the additional output for this.\nSpecify this model in Mplus.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSee the Ex2Model3.out file. The interaction is specified as:\nEExF | EmEx XWITH Fem;      ! Interaction\nThis model gives\nCYNICISM   ON\n    EMEX               0.343      0.105      3.263      0.001\n    EEXF              -0.319      0.135     -2.361      0.018\nwhich implies that the interaction is significant. Substantively, it implies that:\n\nThe effect of Emotional Exhaustion for males (Fem = 0) is 0.343, SE = 0.105, \\(p &lt; .001\\).\nThe effect of Emotional Exhaustion for females (Fem = 1) is 0.319 lower than for men, SE = 0.135, \\(p = .018\\)."
  },
  {
    "objectID": "day3_part2.html#exercise-5",
    "href": "day3_part2.html#exercise-5",
    "title": "Part 2: Full SEM, with mediation and moderation",
    "section": "Exercise 5",
    "text": "Exercise 5\nWe now have a slope for males and a difference in slopes between males and females. If instead, we are interested in the actual slope of females, we can ask Mplus to compute this as an additional statistic using the MODEL CONSTRAINT command. To this end, we first need to name the slopes of interest, using\nCynicism ON EmEx Fem EExF (slopeM interDiff slopeDiff);  \nand subsequently we can use these names to compute new statistic, using\nMODEL CONSTRAINT:\n      new(slopeF);\n      slopeF = slopeM + slopeDiff;\nThis way we will obtain the estimate for the slope of females, including its standard error and p-value.\nSpecify this model in Mplus, and report the results.\n\n\n\n\n\n\nAnswer\n\n\n\n\n\nSee the Ex2Model4.out file. The slope for females (when regressing cynicism on emotional exhaustion is not significantly different from zero:\nNew/Additional Parameters\n    SLOPEF             0.024      0.103      0.233      0.816\nHence, we can conclude that, while for males emotional exhaustion is a positive predictor of cynicism (suggesting that more emotional exhaustion leads to higher levels of cynicism), for females, no such relation was found."
  }
]